## 57. マルコフ連鎖モンテカルロサンプリング

BUGSと同じく、Stanも推定のため、事後分布からのサンプルを生成するのに、マルコフ連鎖モンテカルロ(MCMC)という技術を使います。

### 57.1. モンテカルロサンプリング

モンテカルロ法は、解析的には解けずとも、積分された関数の評価はできるような積分を数値的に近似するために開発されました(Metropolis and Ulam, 1949)。

例を挙げると、確率密度$p(\theta)$の平均$\mu$は次の積分で定義されます。

![$$ \mu = \int_{\Theta} \theta \times p(\theta) d\theta $$](fig/fig01.png)

非常に複雑というほどではないベイズモデルでも、事後密度$p(\theta \mid y)$は、解析的には評価できない積分になってしまいます。事後分布は定数と予測変数$x$にも依存しますが、これ以降は省略して既知のものとします。

ここで、$p(\theta)$から独立なサンプルを抽出できるとして、$\theta^{(1)}, \theta^{(2)},\dots,\theta^{(N)}$を$N$個のそのようなサンプルとします。$p(\theta)$の平均$\mu$のモンテカルロ推定値$\hat{\mu}$は標本平均として与えられます。

![$$ \hat{\mu} = \frac{1}{N}\sum_{n=1}^{N} \theta^{(n)} $$](fig/fig02.png)

確率関数$p(\theta)$が有限の平均と分散を持つなら、大数の法則により、サンプルサイズが増加するとモンテカルロ平均は正しい値に収束することが保証されます。

![$$ \lim_{N \to \infty} \hat{\mu} = \mu $$](fig/fig03.png)

有限の平均と分散を仮定すると、推定誤差は中心極限定理に従うので、$N$の平方根に反比例して減少します。

![$$ |\mu - \hat{\mu}| \propto \frac{1}{\sqrt{N}} $$](fig/fig04.png)

したがって、平均を1桁正確に推定するためには、100倍のサンプルが必要になります。2桁精度を上げるには1万倍のサンプルということになります。モンテカルロ法が、非常に正確な推定値というよりも数桁以内の大雑把な推定に向いているのはこの理由によります。実用上も、ある量を点推定するのに、元になるデータのサンプルが持つ不確実性よりも精度が上がることはありません。そのため、何桁もの精度が得られないことが、統計モデルの実用の際に問題になることは滅多にありません。

### 57.2. マルコフ連鎖モンテカルロサンプリング

マルコフ連鎖モンテカルロ(MCMC)法は、独立したサンプルを単純には抽出できないような状況のために開発されました(Metropolisら, 1953)。

マルコフ連鎖は、確率変数$\theta^{(1)}, \theta^{(2)},\dots$の系列であり、ある変数は、直前の値が与えられたとき、それ以外の変数とは条件付き独立になります。したがって、$\theta = \theta^{(1)}, \theta^{(2)},\dots,\theta^{(N)}$ならば次式のようになります。

![$$ p(\theta) = p(\theta^{(1)}) \prod_{n=2}^{N} p(\theta^{(n)} \mid \theta^{(n-1)}) $$](fig/fig05.png)

Stanでは、その次の状態を生成するのに、60章で述べる方法でハミルトニアンモンテカルロ法を使っています。

Stanおよび他のMCMCサンプラーが生成するマルコフ連鎖は、マルコフ連鎖の中心極限定理に必要という意味でエルゴード的です。大雑把にいうと、$\theta$のある値に他の値から適当な可能性で到達するという意味です。このマルコフ連鎖はまた定常的です。これは、連鎖中の別の位置でも推移確率は異ならないという意味です。したがって、$n,n\prime \ge 0$について、確率関数$p(\theta^{(n+1)} \mid \theta^{(n)})$は$p(\theta^{(n\prime + 1)} \mid \theta^{(n\prime)})$と同じです（慣例に従って確率変数や束縛変数は使い回しをしており、確率関数は引数で区別しています）。

定常マルコフ連鎖は、それぞれが同じ周辺確率関数を持つような状態について平衡分布を持ちます。したがって、$p(\theta^{(n)})$は$p(\theta^{(n+1)})$と同じ確率関数です。Stanでは、平衡分布$p(\theta^{(n)})$は、サンプリングされる確率関数$p(\theta)$であり、一般にはベイズ事後密度です。

MCMC法を使うには、独立サンプルのモンテカルロ法にはない2つの難題があります。1つめの問題は、ランダムに初期化されたマルコフ連鎖が、いつその平衡分布に収束したかを決定することです。2つめの問題は、マルコフ連鎖からの抽出に相関があることです。そうなると、中心極限定理による推定誤差への制約はもはや当てはまりません。これらの問題は次の2つの節で扱います。

### 57.3. 初期化と収束モニタリング

マルコフ連鎖が目的分布からのサンプルを生成するのは、平衡に収束した後だけです。残念ながら、これが保証されるのは理論的には極限においてのみです。実用的には、マルコフ連鎖が収束したかどうかをモニタリングするための診断が必要になります。

#### Potential Scale Reduction

連鎖が平衡分布に収束したかどうかをモニタリングする方法の1つは、ランダムに初期化された別の連鎖と性質を比較することです。これは、Gelman and Rubin (1992)のpotential scale reduction 統計量$\hat{R}$の動機づけとなっているものです。$\hat{R}$統計量は、各連鎖内でのサンプルの分散の平均と、連鎖をまたいでプールしたサンプルの分散との比を測定します。もしすべての連鎖が平衡に達しているなら、これらはすべて同じで$\hat{R}$は1になるでしょう。連鎖が共通の分布に収束していないなら、$\hat{R}$は1より大きくなるでしょう。

GelmanとRubinが推奨するところでは、ばらばらの初期値をパラメータに与えて、独立したマルコフ連鎖を初期化し、すべての値について$\hat{R}$が1.1より小さくなるまでサンプリングします。Stanでは、ユーザーがパラメータの初期値を指定できますし、乱数によってばらばらの初期値を抽出することもできます。

$\hat{R}$統計量は、$M$本のマルコフ連鎖の組$\theta_{m}$について定義されます。このとき、各連鎖は$N$サンプル$\theta_{m}^{(n)}$からなっています。サンプル間分散の推定値は次式です。

![$$ B = \frac{N}{M-1} \sum_{m=1}^{M}(\bar{\theta}_{m}^{(\bullet)} - \bar{\theta}_{\bullet}^{(\bullet)})^{2} $$](fig/fig06.png)

ここで、

![$$ \bar{\theta}_{m}^{(\bullet)} = \frac{1}{N}\sum_{n=1}^{N}\theta_{m}^{(n)} \quad \text{\mbox{かつ}} \quad \bar{\theta}_{\bullet}^{(\bullet)} = \frac{1}{M}\sum_{m=1}^{M}\bar{\theta}_{m}^{(\bullet)} $$](fig/fig07.png)

サンプル内分散は次式です。

![$$ W = \frac{1}{M}\sum_{m=1}^{M}s_{m}^{2} $$](fig/fig08.png)

ここで、

![$$ s_{m}^{2} = \frac{1}{N-1}\sum_{n=1}^{N}(\theta_{m}^{(n)}-\bar{\theta}_{m}^{(\bullet)})^{2} $$](fig/fig09.png)

分散の推定量は次式です。

![$$ \widehat{\mathrm{var}}^{+}(\theta \mid y) = \frac{N-1}{N}W + \frac{1}{N}B $$](fig/fig10.png)

最後に、potential scale reduction 統計量は以下のように定義されます。

![$$ \hat{R} = \sqrt{\frac{\widehat{\mathrm{var}}^{+}(\theta \mid y)}{W}} $$](fig/fig11.png)


#### 不ぞろいな連鎖に対する一般化$\hat{R}$

ここで、各連鎖が異なる数のサンプルからなっていても良いとします。$N_{m}$を連鎖$m$内のサンプルの数とします。このとき、連鎖$m$についての連鎖内平均の式には連鎖のサイズ$N_{m}$を使います。

![$$ \bar{\theta}_{m}^{(\bullet)} = \frac{1}{N_{m}}\sum_{n=1}^{N_{m}}\theta_{n}^{(m)} $$](fig/fig12.png)

連鎖内分散の推定値も同様です。

![$$ s_{m}^{2} = \frac{1}{N_{m}-1}\sum_{n=1}^{N_{m}}(\theta_{m}^{(n)}-\bar{\theta}_{m}^{(\bullet)})^{2} $$](fig/fig13.png)

$\bar{\theta}_{\bullet}^{(\bullet)}$, $B$, $W$といった、連鎖をまたいで平均をとる項は前と同じ定義で、各連鎖が推定値に同じ効果を持つことが保証されます。もし平均がサイズで重み付けされるとしたら、1本の長い連鎖が統計量に強い影響を与え、複数の連鎖を使って収束をモニタリングするという目的は達成できないでしょう。

$N$という項を含むので、推定値$\widehat{\mathrm{var}}^{+}$は一般化する必要があります。最初の項を展開します。

![$$ \frac{N-1}{N}W = \frac{N-1}{N}\frac{1}{M}\sum_{m=1}^{M}\frac{1}{N-1}\sum_{n=1}^{N}(\theta_{m}^{(n)}-\bar{\theta}_{m}^{(\bullet)})^{2} = \frac{1}{M}\sum_{m=1}^{M}\frac{1}{N}\sum_{n=1}^{N}(\theta_{m}^{(n)}-\bar{\theta}_{m}^{(\bullet)})^{2} $$](fig/fig14.png)

第2項です。

![$$ \frac{1}{N}B = \frac{1}{M-1}\sum_{m=1}^{M}(\bar{\theta}_{m}^{(\bullet)}-\bar{\theta}_{\bullet}^{(\bullet)})^{2} $$](fig/fig15.png)

分散の推定量は自然に一般化されます。

![$$ \widehat{\mathrm{var}}^{+}(\theta \mid y) = \frac{1}{M}\sum_{m=1}^{M}\frac{1}{N_{m}}\sum_{n=1}^{N_{m}}(\theta_{m}^{(n)}-\bar{\theta}_{m}^{(\bullet)})^{2} + \frac{1}{M-1}\sum_{m=1}^{M}(\bar{\theta}_{m}^{(\bullet)}-\bar{\theta}_{\bullet}^{(\bullet)})^{2} $$](fig/fig16.png)

連鎖がすべて同じ長さならば、この定義は前の節でのものと等価です。この一般化された分散の推定量と連鎖間分散の推定値は、前の節の$\hat{R}$の式に直接組み込めるでしょう。

#### 分割した$\hat{R}$による非定常性の検出

potential scale reduction 統計量$\hat{R}$を計算する前に、各連鎖を半分ずつ2つに分割することもできます。これにより追加の平均が得られ、連鎖内での非定常性を検出できます。1本の連鎖が次第に増加するような値を取っており、もう1本の連鎖が次第に減少する値を取っているとき、それらはうまく混合してはいないのに、$\hat{R}$の値は1に近い値を取ることがありえます。この場合、各連鎖を2つに分割すると、各連鎖の前半と後半とは混合していないので、$\hat{R}$の値は1よりもかなり大きくなるでしょう。

#### 収束は大域的である

よくある疑問は、パラメータあるいは生成量の一部だけの収束をモニタリングしても良いかどうかというものです。端的に言うと答えは「いいえ」ですが、これについてはこの節でさらに詳しく述べます。

例えば、`lp__`の値を考えましょう。これは、対数事後密度（定数は除く）です。もし`lp__`が収束していないなら、いかなる実用的な意味においても収束したと結論づけるのは誤りです。これは、全ての連鎖は実際にパラメータ空間の別々の部分に存在しているからです。とはいえ、`lp__`の収束を測定するのは、以下に書くようにとりわけトリッキーです。

##### 漸近的かつ過渡的な状態 vs. 平衡

マルコフ連鎖の収束は、モニタリングするパラメータの関数をどう選ぶかに依存しないという意味で大域的な特性です。収束前の「過渡的な状態」と収束後の「平衡」との間には明確な境界はありません。ここで起きていることは、連鎖内の状態の数が無限に近づくにつれ、連鎖内の取り得る状態の分布が目的分布に近づき、その極限では、あらゆる積分可能なモンテカルロ推定量の期待値が真の期待値に収束するということです。ここではウォームアップのようなものはありません。というのは、極限では初期状態の影響は完全に消えているからです。

##### 多変量の場合の関数の収束

$\hat{R}$統計量は、あるマルコフ連鎖とある関数の合成を考えていることになりますので、マルコフ連鎖が収束していれば、マルコフ連鎖と関数の合成は全て収束するでしょう。多変量の場合の関数の収束は、Cramer-Woldの定理により、確率変数のあらゆる周辺和が収束することと等価です。

制約のない空間から制約のある空間への変換は単にもう一つ別の関数となるため、収束には影響ありません。

異なる関数は異なる自己相関を持つ可能性があります。しかしマルコフ連鎖が平衡に達していれば、マルコフ連鎖と関数の合成はすべて一貫して収束するはずです。正式には、収束していないように見える関数があれば、どんなものであれ不安材料となります。あらゆる関数を検証するのは合理的ではないでしょうが、少なくともlp__とその他の測定された量は一貫して収束しているべきです。

`lp__`が目立って異なる点は、位置が急速に変化する傾向があり、そのため外れ値の影響を受けやすいことです。

##### 有限な状態の数

状態の数が有限だとどうなるでしょう? 強い幾何学的エルゴード性を証明できるなら（これは、サンプラーと目的分布に依存します）、連鎖が初期状態を忘れるような有限な時間が、高い確率で存在することを示すことができます。これは自己相関時間とウォームアップ時間の両方についてです。しかし、それが存在して有限であること示せるとしても（ほとんど不可能ですが）、実際の値を解析的に計算することはできません。

したがって実際には、期待値がかなり正確と言えるほどに、有限の抽出数が十分に大きいことを期待することしかできません。ウォームアップのiterationを取り除くことは期待値の正確さを改善しますが、どれだけの有限な数のサンプルを取り除けば十分であるかは保証されません。

##### なぜ$\hat{R}$が一貫しない?

ここで心配すべきことは2つあります。

1つめとして、上に記したように、有限の抽出数ではどれほどであっても、何がしかの初期状態の効果が常に残るでしょう。これは、いくらかの小さな確率（あるいは、自己相関時間がとても大きければ大きな確率）で大きな外れ値を持つという形で現れます。そのような外れ値に頑健な関数（例えば分位数）なら、より安定して見えますし、より良い$\hat{R}$を持つでしょう。そのような外れ値に脆弱な関数なら、脆さが見える結果となるかもしれません。

2つめとして、$\hat{R}$統計量の使用には非常に強い仮定を置いています。とりわけ、関数が正規分布とみなせると仮定していますし、最初の2つのモーメント（訳注: 平均と分散）のみを使い、ある種の独立性を仮定しています。ポイントは、この強い仮定が常に成り立つわけではないということです。とくに、対数事後密度(`lp__`)の分布はほとんど正規分布に見えることがありません。$N$が非常に大きくなっても、裾が長くて$\hat{R}$が大きくなる可能性があります。生の値の代わりに分位数を使うといった小技により、興味のあるサンプルをより正規分布に近づけ、その結果$\hat{R}$をより正確にする傾向を高めることができます。

##### 収束モニタリングについて最後に

「収束」は大域的な特性であり、すべての積分可能な関数について同時に当てはまりますが、$\hat{R}$統計量を採用することには追加の仮定が必要であり、関数すべてに同じようにうまくいくとは限りません。

連鎖間で期待値を比較するだけでも、マルコフ連鎖の正規分布への漸近性に関する信頼性を確認することができ、標準的な検定も適用できることに注意してください。

### 57.4. 有効サンプルサイズ

MCMC法がもたらす技術的な難題の2つめは、一般に連鎖内でサンプルが自己相関を持つことです。これにより、平均や分散、分位数といった、事後分布において興味のある量を推定する際に不確実性が大きくなります。

MCMCの結果の解析一般について、またとくに有効サンプルサイズについての良い入門的な参考文献がGeyer (2011)です。Stanがまさに使っている計算は分割$\hat{R}$の計算に従っていて、これには連鎖をプールした計算（平均）と連鎖内の計算（自己相関）の両方が含まれています。これらはこのマニュアルで紹介されますが、Gelmanほか(2013)でより詳細に説明されています。

#### 有効サンプルサイズの定義

連鎖内の自己相関が推定値の不確実性をどのくらい増やしているかは有効サンプルサイズ(ESS)で測ることができます。独立なサンプルならば、サンプルの数$N$に基づいて中心極限定理が推定値の不確実性を制限します。独立でないサンプルの場合は、独立なサンプルの数は有効サンプルサイズ$N_\mathrm{eff}$に置き換えられます。これは、$N$個の自己相関のあるサンプルと同じ推定能力を持つ独立なサンプルの数です。例えば、推定誤差は、$1/\sqrt{N}$ではなく$1/\sqrt{N_\mathrm{eff}}$に比例します。

ある系列の有効サンプルサイズは、その系列におけるラグの異なる自己相関で定義されます。平均$\mu$、分散$\sigma^2$の同時確率分布$p(\theta)$を持つ連鎖の、ラグ$t \ge 0$での自己相関は次式のように定義されます。

![$$ \rho_{t} = \frac{1}{\sigma^2}\int_{\Theta}(\theta^{(n)}-\mu)(\theta^{(n+t)}-\mu)p(\theta)d\theta $$](fig/fig17.png)

これはまさに、2本の連鎖の間の相関に、位置$t$だけオフセットをつけたものです。MCMCの設定上、$\theta^{(n)}$と$\theta^{(n+t)}$とは同じ周辺分布を持つことがわかっていますから、2つの差の項を掛け算して整理すると次式になります。

![$$ \rho_{t} = \frac{1}{\sigma^2}\int_{\Theta}\theta^{(n)}\theta^{(n+t)}p(\theta)d\theta $$](fig/fig18.png)

自己相関$\rho_t$を持つ過程から生成された$N$サンプルの有効サンプルサイズは次式で定義されます。

![$$ N_\mathrm{eff} = \frac{N}{\sum_{t=-\infty}^{\infty}\rho_{t}} = \frac{N}{1+2\sum_{t=1}^{\infty}\rho_{t}} $$](fig/fig19.png)


#### 有効サンプルサイズの推定

実用的には、問題とする確率関数は簡単には積分できませんし、したがって自己相関も有効サンプルサイズも計算できません。そのかわり、こうした量はサンプル自身から推定される必要があります。この節の残りでは、バリオグラムに基づいた自己相関の推定量、それから複数の連鎖に基づいた有効サンプルサイズについて記述します。簡単のため、各連鎖$\theta_m$の長さはどれも$N$であると仮定しましょう。

有効サンプルサイズを推定する方法の1つは、ラグ$t \in \{0,1,\dots\}$におけるバリオグラム$V_t$に基づくものです。バリオグラムは、（1変量の）サンプル$\theta_m^{(n)}$について以下のように定義されます。ここで、$m \in \{1,\dots,M\}$は連鎖であり、$N_m$は連鎖$m$のサンプルの数です。

![$$ V_t = \frac{1}{M}\sum_{m=1}^{M}\left(\frac{1}{N_{m}-t}\sum_{n=t+1}^{N_{m}}(\theta_{m}^{(n)}-\theta_{m}^{(n-t)})^{2}\right) $$](fig/fig20.png)

前の節で導入した複数連鎖の分散の推定値$\widehat{\mathrm{var}}^{+}$とバリオグラムを使うと、ラグ$t$における自己相関を推定できます。

![$$ \hat{\rho}_{t} = 1 - \frac{V_{t}}{2\widehat{\mathrm{var}}^{+}} $$](fig/fig21.png)

もし連鎖が収束していなければ、分散の推定量$\widehat{\mathrm{var}}^{+}$は分散を過大に推定し、そのため自己相関を過大に推定し、有効サンプルサイズを過小に推定することになります。

$t$が増加すると、相関の推定値$\hat{rho}_t$にノイズが増えるため、通常は$\hat{rho}_t > 0$となるような$\hat{rho}_t$の初期の推定値だけが使われます。$T\prime$を、$\rho_{T\prime + 1} < 0$となるような最初のラグとします。

![$$ T' = \mathop{\mathrm{argmin}}\limits_{t} \hat{\rho}_{t+1} < 0 $$](fig/fig22.png)

有効サンプルサイズの推定量は次式のように定義されます。

![$$ \hat{N}_\mathrm{eff} = \frac{1}{2}\frac{MN}{1 + \sum_{t=1}^{T\prime}\hat{\rho}_{t}} $$](fig/fig23.png)

（訳注: Gelmanほか(2013)では、$\hat{N}_\mathrm{eff} = \frac{MN}{1 + 2 \sum_{t=1}^{T}\hat{\rho}_{t}}$、ただし$T$は$\hat{\rho}_{T+1} + \hat{\rho}_{T+2}$が負になるような最初の奇数、となっています。）

適正な自己相関が生じ得るのは、ラグが奇数のときだけです(Geyer, 2011)。自己相関はペア間で足し合わせることにより、positive modulo estimator noiseとなることが保証されます。これは、Geyer (2011)において多数の打ち切り基準が提案された背景になっています。Stanは（まだ）ペアでの期待値を計算しませんが、これは、そのつくりからNUTSが負の自己相関の領域をほぼ避けるためです。したがって、負の自己相関が現れたところで打ち切りを行うのは、自己相関推定量の中でノイズが大半を占めるようになったら打ち切りを行うことの合理的な近似になっています。

Stanはすべてのラグに対する自己相関を同時に計算します。その際、適当なパディングを付与して、Eigenの高速フーリエ変換(FFT)パッケージを利用します。自己相関の計算にFFTを使うことの詳細についてはGeyer (2011)を参照してください。

#### サンプルの間引き

一般的な状況では、自己相関$\rho_t$は、ラグ$t$が増加するにつれて減少します。このようなとき、サンプルを間引くことにより、自己相関が減るでしょう。例えば、以下の2つの方法のうちの1つで1000サンプルを生成するとします。

1. 収束後に1000サンプルを生成し、そのすべてを保存する。
2. 収束後に10000サンプルを生成し、10個ごとにサンプルを保存する。

両方とも1000サンプルを生成するとはいえ、間引きのある2番目の方法がより有効なサンプルを生成するでしょう。これは、間引かれた系列の自己相関$\rho_t$は、間引かれていないサンプルの$\rho_{10t}$に相当するからです。そのため、自己相関の和は小さくなり、そして有効サンプルサイズは大きくなるでしょう。

一方、メモリとデータの容量に問題がないなら、10000サンプルすべてを保存する方が、1000サンプルに間引くよりも有効サンプルサイズは大きくなるでしょう。


