## 21. 問題のある事後分布

数学的に言うと、正則な事後分布であればベイズ推定はできていて、話はそこで終わりです。有限な分散さえも、あるいは有限な平均さえも必要ではありません。必要なのは有限な積分だけです。それにもかかわらず、モデリングは厄介な仕事で、経験を積んだモデル作成者でも非正則な事後分布^[訳注: 原文はpriorsとなっていますが、文脈からすると事後分布です。]ができるようなモデルをコーディングしてしまうことがあります。さらに、数学的には正しいにも関わらず、実用的には挙動がおかしい事後分布もあります。この章では、問題のある事後分布を推定してしまうモデルについて、ベイズ推定一般として、あるいはStanでの実用面から議論します。

### 21.1. 回帰での予測変数の共線性

この節では、識別可能性に関する古典的な問題について議論します。この問題は、事後密度を尾根状にし、サンプリングと推定の両方をめちゃくちゃにしてしまうというものです。

#### 共線性の例

##### 余分な切片

共線性の最初の例は、余分な切片パラメータを含むという人工的なものです。^[この例は、Richard McElreathがStan users groupで提起しました。BUGSおよびJAGSで使われるギブズサンプリングと、Stanで使われるハミルトニアンモンテカルロ(HMC)およびno-U-turnサンプラー(NUTS)との挙動の違いについての質問の中でのことです。] $n \in 1:N$についての観測値$y_n$、2つの切片パラメータ$\lambda_1$と$\lambda_2$、スケールパラメータ$\sigma > 0$があり、サンプリング分布が以下のようであるとします。

![$$ y_n \sim \mathsf{Normal}(\lambda_1 + \lambda_2, \sigma) $$](fig/fig01.png)

任意の定数$q$について、$q$を$\lambda_1$に加え、$\lambda_2$から引くならば、$y$のサンプリング密度は不変です。

![$$ p(y \mid \lambda_1, \lambda_2, \sigma) = p(y \mid \lambda_1 + q, \lambda_2 - q, \sigma) $$](fig/fig02.png)

その結果、非正則一様事前分布$p(\mu, \sigma) \propto 1$からは非正則事後分布が導かれます。この非正則性が生じるのは、$\lambda_1+q, \lambda_2-q$ ^[訳注: 原文では、$\lambda_1+q, \lambda_1-q$ですが、誤植のようです。]の近傍では、どんな$q$についても質量が同じになるからです。したがって、$\lambda_1=1000000000$かつ$\lambda_2=-1000000000$の近傍でも、$\lambda_1=0$かつ$\lambda2=0$の近傍と同じ時間がサンプラーには必要になりますし、さらにもっと離れた値でも同様です。

このモデルの周辺事後分布$p(\lambda_1,\lambda_2 \mid y)$はしたがって非正則です。^[$\sigma$の周辺事後分布$p(\sigma \mid y)$はこの場合、少なくとも異なる2つのデータ点がある限りは正則です。] この非正則性は、図21.1の左側に図示したように、視覚的には事後密度の尾根として表されます。このモデルの尾根は、$c$をある定数として、$\lambda_2 = -\lambda_1 + c$という直線^[訳注: 原文では、$\lambda_2 = \lambda_1 + c$となっていますが、誤りのようです。]に沿ってできます。

このモデルを、単一の切片パラメータ$\mu$をもち、以下のサンプリング分布をもつ単回帰と比較しましょう。

![$$ y_n \sim \mathsf{Normal}(\mu, \sigma) $$](fig/fig03.png)

この場合には、非正則事前分布であっても、異なる値を持つ少なくとも2つのデータ点$y_n$がある限り事後分布は正則となります。

##### IRTモデルにおける能力と難易度

項目反応理論（IRT）モデルで、生徒$j \in 1:J$が能力$\alpha_j$を持ち、試験項目$i \in 1:I$が難易度$\beta_i$を持つとします。観測データは$I \times J$次元配列で、エントリー$y_{i,j} \in \{0,1\}$は、$y_{i,j}=1$のとき生徒$j$が問題$i$に正答したことを示すようにコード化します。このデータのサンプリング分布は以下のようになります。

![$$ y_{i,j} \sim \mathsf{Bernoulli}(\mathrm{logit}^{-1}(\alpha_j - \beta_i)) $$](fig/fig04.png)

任意の定数$c$について、定数$c$を能力すべてに加え、かつ難易度すべてにも加えると、$y$の確率は変わりません。^[訳注: 原文では$c$を能力に加え、難易度から引くとなっていますが、上の式からすると双方に加えるのが正しいようです。]

![$$ p(y \mid \alpha, \beta) = p(y \mid \alpha + c, \beta + c) $$](fig/fig05.png)

このため、上で議論した2つの切片を持つ回帰の多変量版が出現することになります。

##### 一般的な共線性のある回帰予測変数

共線性の問題の一般型は、回帰の予測変数が共線であるときに発生します。例えば、直線回帰のサンプリング分布を考えます。

![$$ y_n \sim \mathsf{Normal}(x_n \beta, \sigma) $$](fig/fig06.png)

$y$は$N$次元の観測値ベクトル、$x$は$N \times K$の予測変数行列、$\beta$は$K$次元の係数ベクトルです。

ここで、予測変数行列の列$k$が列$k'$の定数倍になっているとします。すなわち、すべての$n$について$x_{n,k}=cx_{n,k'}$となるような定数$c$が存在するとします。この場合、係数$\beta_k$と$\beta_{k'}$は予測値を変えずに共変動できます。そのため、任意の$d \neq 0$について次式が成り立ちます。

![$$ p(y \mid \dots,\beta_k,\dots,\beta_{k'},\dots,\sigma) = p(y \mid \dots,d\beta_k,\dots,\frac{d}{c}\beta_{k'},\dots,\sigma) $$](fig/fig07.png)
^[訳注: $x_{k'}$の係数は正しくは$(\beta_{k'}+c(1-d)\beta_{k})$のようです。]

予測変数行列の列が、上の議論のような完全な共線ではなくとも、共線に近ければ推定に同じような問題が発生します。

##### IRTでの乗数の問題

IRTモデルで、各々の質問に識別力パラメータ$\delta_i$を加えるとします。データをサンプリングするモデルは次式です。

![$$ y_{i,j} \sim \mathsf{Bernoulli}(\mathrm{logit}^{-1}(\delta_i (\alpha_j - \beta_i))) $$](fig/fig08.png)

任意の定数$c \neq 0$について、$\delta$を$c$倍し、$\alpha$と$\beta$を$c$で割っても、尤度は同じです。

![$$ p(y \mid \delta, \alpha, \beta) = p(y \mid c\delta, \frac{1}{c}\alpha, \frac{1}{c}\beta) $$](fig/fig09.png)

もし$c < 0$ならば、密度を変えずに、$\alpha$および$\beta$、$\delta$のすべての成分の符号が反転します。

##### SoftmaxでのK vs. K-1パラメータ

$K$単体（すなわち、合計すると1になる、非負の値からなる$K$次元ベクトル）をパラメータ化するためには、$K-1$個のパラメータだけが必要です。なぜなら、$K$番目のパラメータは、最初から$K-1$番目までの合計を1から引いた値になるからです。したがって、$\theta$を$K$単体とすると次式が成り立ちます。

![$$ \theta_K = 1 - \sum_{k=1}^{K-1}\theta_k $$](fig/fig10.png)

softmax関数（35.11節参照）は、線形予測子の$K$次元ベクトル$\alpha$を$K$単体$\theta$にマッピングします。つまり$\theta = \mathrm{softmax}(\alpha)$で、定義は次式です。

![$$ \theta_k = \frac{\exp(\alpha_k)}{\sum_{k'=1}^{K}\exp(\alpha'_k)} $$](fig/fig11.png)

softmax関数は多対1関数です。パラメータ$\alpha$に制約がないと、識別可能性が失われます。とくに、すべての$\alpha_k$に定数を足したり引いたりしても、おなじ単体$\theta$となります。

#### 不変さを軽減する

前の節で議論した例はすべて、データの確率密度を変えないままパラメータの平行移動や拡大縮小ができるというものです。この問題を軽減する方法はいくつかあります。

##### 余分なパラメータや予測変数を取り除く

複数の切片、$\lambda_1$と$\lambda_2$がある場合には、余分な切片を取り除くのが最も単純な解決法です。これによりモデルは、単一の切片パラメータ$\mu$を持ち、サンプリング分布は$y_n \sim \mathsf{Normal}(\mu, \sigma)$となります。同じ解決法を、共線性の問題にも使えます。予測変数行列$x$から列を1つ取り除くだけです。

##### ピン留めパラメータ

識別力パラメータのないIRTモデルは、パラメータの1つを固定した値（普通は0）にピン留めすることで固定することができます。例えば、最初の生徒の能力$\alpha_1$を0に固定することができます。このとき、その他の生徒すべての能力パラメータは生徒1に対する相対値と解釈できます。同様に難易度パラメータは、生徒1の解答能力に対する相対値と解釈されます。

この解決法は、質問の識別力パラメータ$\delta_i$を導入すると発生する、乗数による不変性を扱うには十分ではありません。この問題を解決するには、識別力^[訳注: 原文はdifficultyですが、discriminationの誤りと思われます]パラメータの1つ、たとえば$\delta_1$にも制約をつけなくてはなりません。乗数による不変性は、加算とは異なり、非零の値に制約しなければなりません。都合が良いのは1とすることです。このとき、識別力パラメータはすべて、項目1の識別力に対する相対値として解釈されるでしょう。

softmax($\alpha$)の多対1の性質は、$\alpha$の成分の1つをピン留めすることで軽減するのは普通です。例えば、$\alpha_K = 0$と固定します。そうすると、$K-1$次元の制約のないパラメータから、$K$単体へ、1対1対応となります。これが、単体として制約されるパラメータをStanで定義するおおまかな方法です。正確な定義は58.6節を参照してください。$K-1$次元ベクトルから単体を生成するStanコードは以下のとおりです。

```
vector softmax_id(vector alpha) {
  vector[num_elements(alpha) + 1] alphac;
  for (k in 1:num_elements(alpha))
    alphac[k] = alpha[k];
  alphac[num_elements(alphac)] = 0;
  return softmax(alphac);
}
```

##### 事前分布を加える

ここまで、パラメータの事前分布が非正則一様事前分布であるとしてモデルを議論してきました。

こうした不変性の問題に対する、より一般的なベイジアンの解決法は、パラメータに正則な事前分布を与えることです。加法的でも、乗法的でも、どちらの不変性に由来する問題でも、この方法を使って解決できます。

例として、複数の切片に正規分布を事前分布として与えます。

![$$ \lambda_1,\lambda_2 \sim \mathsf{Normal}(0, \tau) $$](fig/fig12.png)

$\tau$を定数値のスケールとすると、事後最頻値が$\lambda_1 = \lambda_2$となる点に位置することが保証されます。なぜならこれにより、$\log\mathsf{Normal}(\lambda_1 \mid 0, \tau) + \log\mathsf{Normal}(\lambda_2 \mid 0, \tau)$が最小化されるからです。^[ラプラス分布を事前分布にすること（あるいは罰則付き最尤推定のL1正規化）は加法的な不変性を取り除くには十分ではありません。縮小はしますが、それ自体がパラメータを識別するというわけではありません。$\lambda_1$に定数を加え、$\lambda_2$からそれを引くと、事前分布で同じ値となる場合があるからです。] 2つの切片を持つモデルに事前分布を加えたものを図21.1の中央に示します。図21.1の右側は、単一の切片を持つように再パラメータ化した結果です。

![図21.1](fig/improper-proper-posterior.png)
図21.1: 事前分布なしの2切片パラメータ化、平均0標準偏差1の正規事前分布の2切片パラメータ化、事前分布なしの1切片再パラメータ化のそれぞれの事後分布。3つの場合とも、平均0標準偏差1の正規分布から抽出された100データ点について事後分布をプロットしています。左）2切片パラメータ化は、北西方向と南東方向とに無限に伸びる尾根状の非正則事後分布^[訳注: 原文はpriorですが、文脈からすると事後分布と思われます。]となります。中）平均0標準偏差1の正規事前分布を切片に対して加えると正則事後分布になります。右）事前分布なしの単一切片パラメータ化も正則事後分布が得られます。

$K$単体パラメータ化$\theta = \mathrm{softmax}(\alpha)$を、制約なしの$K$次元ベクトル$\alpha$について識別するための別の方法は、$\alpha$の各成分が、ある固定した位置パラメータをもつ事前分布に従うとすることです（すなわち、位置が変わるような階層事前分はとくに避けるようにします）。$\alpha_K = 0$とピン留めする方法では、$K$番目の値への相対値として$K-1$個の値をモデリングしていました。事前分布に基づく方法では、そうではなく、$K$個の値を等しく対称的に扱ってモデリングします。一方で、ピン留めのパラメータ化の方が通常は、（事前分布で制約された）空間内の動きに余分な自由度がないので、統計学的にはより効率的です。

##### 漠然事前分布、強情報事前分布、弱情報事前分布

不変性を解決するために事前分布を加える際には注意が必要です。事前分布の幅が広すぎると（すなわち漠然すぎると）、理論的には解決するとしても、実際にはサンプラーがやはり動くのに苦労するということになるでしょう。

理想的には、モデリングする問題についての本質的な知識に基づいて、現実的な事前分布を定式化するのがよいでしょう。そのような事前分布なら、事前の知識に基づいた適切な強さを選択できます。強い事前の情報があるときには、強情報事前分布を使うとよいでしょう。

強い事前の情報がないときには弱情報事前分布を使って、事後分布中でデータを圧倒しないことと、推定の計算を制御することとの適切なバランスをとります。たいていの問題では、推定値がどのくらいのスケールになるか、少なくとも何らかの見解をモデル作成者は持っているでしょう。そして、データを圧倒しないような、しかし事後分布を十分に制御できるような、識別可能性の目的にあう事前分布を選ぶことができます。

事前分布は、IRTモデルにおける加法的な不変性を制御するためにも同じように使えます。典型的には単純に、スケールを制御する強い事前分布を生徒の能力パラメーター$\alpha$に設定することで、基本的なIRTモデルにおける加法的な不変性と、質問項目の識別力パラメータを含む拡張モデルにおける乗法的な不変性を制御します。そのような事前分布は、解析対象についての事前知識を増やすものではありません。そして、質問項目の難易度についての事前分布は、解析対象の事前知識に基づいて、情報のある事前分布もしくは弱情報事前分布を選ぶとよいでしょう。

### 21.2. 混合分布モデルでのラベルスイッチング

回帰モデルにおいて共線性がある場合、事後分布を最大化するパラメータの値は無限個あります。その一方で、混合分布モデルの成分を入れ替えることができる場合、事後分布を最大化するパラメータの値は有限個ですが、複数あるために問題のある事後分布となります。

#### 混合分布モデル

2つの位置パラメータ$\mu_1$と$\mu_2$をもつ正規混合分布モデルを考えます。スケールはともに$\sigma > 0$で、混合率を$\theta \in [0, 1]$とすると尤度は次式になります。

![$$ p(y \mid \theta,\mu_1,\mu_2,\sigma) = \prod_{n=1}^{N}(\theta\mathsf{Normal}(y_n \mid \mu_1,\sigma) + (1 - \theta)\mathsf{Normal}(y_n \mid \mu_2,\sigma)) $$](fig/fig13.png)

ここでの問題は、次式のように混合成分が入れ替わりうることです。

![$$ p(\theta,\mu_1,\mu_2,\sigma \mid y) = p((1 - \theta), \mu_2, \mu_1, \sigma \mid y) $$](fig/fig14.png)

この問題は、クラスタリングモデルのように、混合成分$K$の数が大きくなるにつれて悪化します。$K!$個の同一の事後最大値ができます。

#### 収束モニタリングと有効サンプルサイズ

事後分布の収束と有効サンプルサイズの分析も混合分布モデルでは難しい問題です。例えば、Stanが報告する$\hat{R}$収束統計量も、有効サンプルサイズの計算も、ラベルスイッチングで不正確になります。問題は、これらの計算の鍵となる要素である事後平均がラベルスイッチングの影響を受けることにあります。$\mu_1$の事後平均が$\mu_2$の事後平均に等しくなり、$\theta$の事後平均が、データによらず常に1/2になってしまいます。

#### 不変の推定もある

ある意味、混合成分のインデックス（あるいはラベル）は重要ではありません。事後予測推測は、混合成分が識別できなくとも可能です。例えば、新しい観測値の対数確率は、混合成分が識別されるかに依存しません。ラベルスイッチングが起きるモデルにおいて正しいベイズ推定値とは、ラベルスイッチングが起きても不変なものだけです。パラメータの事後平均は、ラベルスイッチングに対して不変ではないので意味がありません。例えば、2成分の混合分布モデルにおける$\theta$の事後平均は常に1/2となるでしょう。

#### 非常に多峰な事後分布

この場合には、理論的には、事後予測推測に含まれる積分はすべてうまくいくでしょうから、推定の問題はないはずです。実用上の問題は計算にあります。

そのような不変の推定が実用的にも実行可能であるかどうかは、まったく別の問題です。たった1つの事後最頻値を見つけるのにも難儀するのがほぼ毎度のことです。ましてや、確率質量に従って、複数ある局所最大値のうちの隣のものと探索のバランスをとるなど、さらに難儀なことです。ギブズサンプリングでは、$\mu_1$が、現在の$\mu_2$と$\theta$の値に条件づけられてサンプリングされているときに、今まで到達したことがない新たな局所最頻値へと移動することはなさそうです。HMCとNUTSではその場合、2つの局所最頻値のまわりの2つの「くぼみ」のうちの1つにサンプラーがはまってしまうことにより、ランダムな運動量の割り当てからは、一方の局所最頻値から他方の局所最頻値へと動くための十分なエネルギーを集められないということになります。

正則な事後分布であっても、混合分布モデルで成分の数が増える場合のように、指数関数よりも速く局所最頻値の数が増える場合には、既知のサンプリングと推定の技法のすべてが非効率的となることが知られています。

#### 修正のハック

いくつかのハック（つまり「トリック」）が、ラベルスイッチングにより起こる問題への実用的な対処のために提案され、採用されています。

##### パラメータの順序の制約

よく使われる戦略の1つは、成分を識別するようにパラメータに制約を課すことです。例えば、上で議論した2成分正規混合分布モデルに$\mu_1 < \mu_2$という制約を課すことを考えましょう。この方法では、反対の順序$\mu_1 > \mu_2$に実質的な確率質量が存在する場合に問題が起こりえます。この場合、その制約によって事後分布が影響を受け、$\mu_1$と$\mu_2$における真の事後分布の不確実性は、制約のあるモデルではとらえることができません。さらに、ある事象の生起確率を事後に推定する標準的な方法においても問題が発生します。例えば、$\Pr[\mu_1 > \mu_2]$を推定するため$M$個の事後サンプルを使おうとすると失敗します。これは、事後分布がモデルの制約を守るため、次式の推定量による推定値が0になるからです。

![$$ \Pr[\mu_1 > \mu_2] \approx \sum_{m=1}^{M}\mathrm{I}(\mu_1^{(m)} > \mu_2^{(m)}) $$](fig/fig15.png)

##### 単一の最頻値のまわりでの初期化

よく使われる別の方法は、1個の連鎖で動かすか、現実的な値の近くでパラメータを初期化することです。^[テンパリング法が、局所最頻値を探す自動化した方法と見られることもあります。しかし、ほとんどのMCMCテンパリング法は、止めることが難しく、そのまま局所最頻値を探し続けます。Swendsen and Wang, 1986; Neal, 1996bを参照。] もっともな初期値を見つけて、マルコフ連鎖内でスイッチが起きなければ、これは、強い制約を課す方法よりもうまくいくことがあります。結果は、すべての連鎖が、事後分布における特定の局所最頻値の近くに張り付きます。

### 21.3. 混合分布モデルで成分がつぶれる

サンプリングまたは最適化の間に、混合分布モデルの2つの混合成分がつぶれて同じ値になることがあります。例えば、$K$個の正規分布からなる混合分布で、$i \neq j$について、$\mu_i = \mu_j$かつ$\sigma_i = \sigma_j$となることがあります。

これは典型的には、MCMCの初期化または最適化によりサンプリングの初期に発生するか、あるいはMCMC中のランダムな移動により発生するでしょう。与えられた抽出（$m$）において、いったん複数のパラメータが同じ値になってしまうと、現在のパラメータの値と、成分がつぶれていないときの値との間に質量の谷があるために、そこから出られなくなることがあります。

ウォームアップ中のステップサイズを小さくすることや、各混合成分がどのインデックスになりやすいかを定める強い事前分布が役に立つかもしれません。もっと極端な手段は、いくつかのパラメータがつぶれる可能性を考えて、混合成分を追加しておくことです。

一般に$K$が1よりも大きくなると、混合分布モデルで、$K$個の正しい混合成分を正確に復元することはきわめて困難です。（そうです。2成分の混合分布でさえ、この問題は起こりえます。）

### 21.4. 上下限のない密度での事後分布

場合によっては、パラメータがある極や境界に近づいて、際限なく事後密度が大きくなるということがあります。そのようなときは、事後最頻値はありませんし、サンプリングされたパラメータが制約の境界に近づくので、数値的安定性の問題が起こることがあります。

#### スケールが変わる混合分布モデル

そのような例の1つは、スケール$\sigma_1$と$\sigma_2$が成分によって変わる2項混合分布モデルです。位置は$\mu_1$と$\mu_2$とします。この状況で、ある$n$について、$\sigma_1 \rightarrow 0$かつ$\mu_1 \rightarrow y_n$で、密度が際限なく大きくなります。すなわち、混合成分の1つの質量のすべてが、単一のデータ項目$y_n$の周囲に集中するのです。

#### ゆがみのあるデータと弱い事前分布のベータ二項モデル

際限のなく大きくなる密度のもうひとつの例は、$\mathsf{Beta}(\phi \mid 0.5, 0.5)$のような事後分布で発生するものです。これは非常に「弱い」ベータ事前分布がデータのない群に使われているときに発生することがあります。この密度は$\phi \rightarrow 0$かつ$\phi \rightarrow 1$で際限なく大きくなります。同様に、「弱い」ベータ事前分布のベルヌーイ尤度モデルも次式のような事後分布になります。

![$$\begin{array}{ll} p(\phi \mid y) &\propto \mathsf{Beta}(\phi \mid 0.5, 0.5) \times \prod_{n=1}^{N}\mathsf{Bernoulli}(y_n \mid \phi)\\ &= \mathsf{Beta}(\phi \mid 0.5 + \sum_{n=1}^{N}y_n, 0.5 + N - \sum_{n=1}^{N}y_n) \end{array}$$](fig/fig16.png)

もし$N=9$で、各々の$y_n=1$であれば、事後分布は$\mathsf{Beta}(\phi \mid 9.5, 0.5)$になります。この事後分布は$\phi \rightarrow 1$で際限なく大きくなります。にもかかわらず、事後分布は正則で、事後最頻値がないにも関わらず、事後平均は正確に0.95と明確に定義されます。

##### 制約のあるスケール vs. 制約のないスケール

この問題ではStanは、制約のある(0, 1)空間を直接サンプルすることはしませんし、制約のない密度の値を直接あつかうこともしません。そうではなく、確率の値$\phi$が($-\infty$, $\infty$)にロジット変換されます。境界の0と1はそれぞれ$-\infty$と$\infty$になります。ヤコビアンの調整はStanが自動的に行なうので、制約なしの密度は正則であることが保証されます。(0, 1)の特定の場合の調整は$\log\mathrm{logit}^{-1}(\phi)+\log (1 - \mathrm{logit}^{-1}(\phi))$です。^[訳注: 原文は誤っているようです。]導出は58.4節を参照してください。

しかし、2つの問題がまだ出てきます。1つ目として、$\phi$の事後質量が境界の1近くにある場合には、ロジット変換されたパラメータは非常に長いパスを掃き出すしかなくなり、そのためno-U-turnサンプラーが課すU-turn条件ばかりが満たされ、うまくサンプリングできなくなることがあります。2つ目の問題は、制約のない空間から制約のある空間への逆変換のときに、0にアンダーフローしたり、1にオーバーフローしたりするおそれがあることです。これは、制約のないパラメーターが無限でなくても発生します。同様の問題は、ロジスティック回帰の期待値の項でも発生します。ベルヌーイ分布と2項分布ではロジットスケールのパラメータ化がより安定なのはこの理由によります。

### 21.5. 上下限のないパラメータでの事後分布

場合によっては、事後密度は際限なく大きくはならないのに、密度のとる値を次第に増加させながらパラメータが際限なく大きくなることがあります。前の節で議論した、密度が際限なく大きくなるモデルと同様に、そのようなモデルにも事後最頻値はありません。

#### ロジスティック回帰での分離可能性

$N$個の結果変数$y_n \in \{0, 1\}$と、$N \times K$行列の予測変数$x$、$K$次元の係数ベクトル$\beta$からなるロジスティック回帰モデルを考えます。サンプリング分布は次式です。

![$$ y_n \sim \mathsf{Benoulli}(\mathrm{logit}^{-1}(x_n \beta)) $$](fig/fig17.png)

ここで、予測変数行列の$k$列が、$y_n = 1$のときだけに$x_{n,k} > 0$となるとします。この条件は「分離可能性」として知られます。この場合、観測データについての予測の正確さは、$\beta_k \rightarrow \infty$となるにつれ、改善され続けます。$y_n = 1$のとき、$x_n \beta \rightarrow \infty$で、$\mathrm{logit}^{-1}(x_n \beta) \rightarrow 1$となるからです。

分離可能性の問題のあるときは、尤度に最大値はありませんから、最尤推定値もありません。ベイズの観点からいうと、事後分布は非正則ですから、したがって$\beta_k$の周辺事後平均も定義されません。ベイズモデルではこの問題は通常、$\beta$に正則事前分布を与えて、事後分布が正則であることを保証することにより解決します。

### 21.6. 一様な事後分布

区間[0, 1]で定義され、一様事前分布$\mathsf{Uniform}(\psi \mid 0, 1)$が与えられたパラメータ$\psi$を含むモデルがあるとします。ここで、データには$\psi$についての情報が何もないとすれば、事後分布も$\mathsf{Uniform}(\psi \mid 0, 1)$となります。

$\psi$には最尤推定値がありませんが、事後分布は閉じた区間で一様ですから、正則です。一様な事後分布[0, 1]の場合、$\psi$の事後平均は1/2と明確に決まります。事後最頻値はありませんが、それにもかかわらず事後予測の推定は問題なくできるでしょう。$\psi$の予測値を[0, 1]のすべての点で単純に積分（すなわち平均）すればよいのです。

### 21.7. 問題のある事前分布によるサンプリングの難しさ

非正則な事後分布では、事後分布を適切に探索することは理論的には不可能です。BUGSやJAGSで実行されるギブズサンプリングでも、そのような非正則な事後分布から適切にサンプリングすることは不可能です。しかし、それにも関わらず、21.1節で議論し、図21.1で図示した2切片モデルのような例に直面したとき、ギブズサンプリングは、Stanで実行されるハミルトニアンモンテカルロのサンプリングとは実際はまったく異なる挙動を示します。

#### ギブズサンプリング

BUGSやJAGSで実行されるギブズサンプリングは、この識別されないモデルについて効率的で、うまく動作するように見えるかもしれませんが、前の小節で議論したように、実際には事後分布を適切には探索しないでしょう。

初期値$\lambda_{1}^{(0)}$, $\lambda_{2}^{(0)}$で起こることを考えましょう。ギブズサンプリングはiteration $m$で以下の抽出を行なって進行します。

![$$\begin{array}{ll} \lambda_1^{(m)} &\sim p(\lambda_1 \mid \lambda_2^{(m-1)}, \sigma^{(m-1)},y)\\ \lambda_2^{(m)} &\sim p(\lambda_2 \mid \lambda_1^{(m)}, \sigma^{(m-1)},y)\\ \sigma^{(m)} &\sim p(\sigma \mid \lambda_1^{(m-1)}, \lambda_2^{(m)}, y) \end{array}$$](fig/fig18.png)

ここで、$\lambda_1$（$\lambda_2$の抽出も対称です）の抽出を考えます。このモデルでは共役であり、したがって非常に効率的に抽出ができます。このモデルでは、次の$\lambda_1$が抽出可能な範囲は、現在の$\lambda_2$と$\sigma$の値により非常に制限されています。ギブズサンプラーは非常に速く動き、外見上はもっともらしい$\lambda_1 + \lambda_2$の推定値を与えるでしょう。しかし、事後分布の範囲全体を探索はしません。初期値付近をゆっくりランダムウォークしているに過ぎないのです。このランダムウォークの挙動は、事後分布の相関が非常に大きいときのギブズサンプリングに典型的です。これが、事後分布でパラメータが相関を持つモデルでは、ギブズサンプリングよりもハミルトニアンモンテカルロが好まれる主要な理由です。

#### ハミルトニアンモンテカルロのサンプリング

Stanが実行するハミルトニアンモンテカルロ(HMC)は、事後分布でパラメータに相関があるモデルでの事後分布の探索をはるかに効率的に行ないます。とくにこの例では、ハミルトニアンダイナミクス（すなわち、負の対数事後分布により定義される場において、ランダムな運動量で与えられる、架空粒子の運動）はポテンシャルエネルギーにより定義される谷（対数事後確率における尾根が、ポテンシャルエネルギーにおける谷に相当します）に沿って登ったり降りたりします。実際には、$\lambda_1$と$\lambda_2$のランダムな運動量についてさえも、対数事後確率の勾配により、相関について調整が行なわれ、シミュレーションでは$\lambda_1$と$\lambda_2$が、事後対数密度の尾根に相当する谷に沿って反対方向に動かされるでしょう（図21.1参照）。

#### No-U-Turnサンプリング

Stanのデフォルトのno-U-turnサンプラー(NUTS)はさらにもっと効率的に事後分布を探索します（Hoffman and Gelman (2011, 2014)を参照）。NUTSは、パラメータの値を表す架空粒子の運動を、それがUターンするまでシミュレートします。問題のある事後分布からサンプリングする場合、Uターンしないでポテンシャルエネルギーの谷をいつまでも降下することになり、ほとんどの場合うまくいきません。実際に起きることは、シミュレーションの多くのiterationでリープフロッグの最大ステップ数に到達し、対数確率と勾配の評価回数（デフォルトのように最大tree depthが10ならば、1000となります）が非常に大きな数となることです。したがって、サンプリングは非常に遅いように見えるでしょう。これは非正則事後分布を示すもので、NUTSアルゴリズムや実装のバグではありません。単純に、非正則な事後分布からサンプリングすることは不可能なのです。したがって、非正則な事後分布の場合に明確に失敗し、事後分布の非常に長いパスを掃き出すという分かりやすい結果を得ることは、一般的なHMCと特定のNUTSの挙動としては当然で安心できるものです。

#### 例: Stanでのあてはめ

識別不可能なモデルや弱くしか識別されないモデルからのサンプリングの問題を描写するため、パラメータの識別可能性の程度を増やしつつ、3つのモデルに当てはめを行ないます。これらのモデルの事後分布は図21.1に図示したものです。最初のモデルは、21.1節で議論した、2つの位置パラメータがあり、事前分布はない識別されないモデルです。

```
data {
  int N;
  real y[N];
}
parameters {
  real lambda1;
  real lambda2;
  real<lower=0> sigma;
}
transformed parameters {
  real mu;
  mu = lambda1 + lambda2;
}
model {
  y ~ normal(mu, sigma);
}
```

2番目のモデルは、前のモデルの`model`ブロックに、`lambda1`と`lambda2`の事前分布を加えたものです。

```
  lambda1 ~ normal(0, 10);
  lambda2 ~ normal(0, 10);
```

3番目は、単一の位置パラメータを持ちますが、事前分布は指定しません。

```
data {
  int N;
  real y[N];
}
parameters {
  real mu;
  real<lower=0> sigma;
}
model {
  y ~ normal(mu, sigma);
}
```


##### 2個のスケールパラメータ、非正則事前分布
```
Inference for Stan model: improper_stan
Warmup took (2.7, 2.6, 2.9, 2.9) seconds, 11 seconds total
Sampling took (3.4, 3.7, 3.6, 3.4) seconds, 14 seconds total
                  Mean     MCSE   StdDev        5%       95%  N_Eff  N_Eff/s  R_hat
lp__          -5.3e+01  7.0e-02  8.5e-01  -5.5e+01  -5.3e+01    150       11    1.0
n_leapfrog__   1.4e+03  1.7e+01  9.2e+02   3.0e+00   2.0e+03   2987      212    1.0
lambda1        1.3e+03  1.9e+03  2.7e+03  -2.3e+03   6.0e+03    2.1     0.15    5.2
lambda2       -1.3e+03  1.9e+03  2.7e+03  -6.0e+03   2.3e+03    2.1     0.15    5.2
sigma          1.0e+00  8.5e-03  6.2e-02   9.5e-01   1.2e+00     54      3.9    1.1
mu             1.6e-01  1.9e-03  1.0e-01  -8.3e-03   3.3e-01   2966      211    1.0
```

##### 2個のスケールパラメータ、弱情報事前分布
```
Warmup took (0.40, 0.44, 0.40, 0.36) seconds, 1.6 seconds total
Sampling took (0.47, 0.40, 0.47, 0.39) seconds, 1.7 seconds total
                 Mean     MCSE   StdDev        5%    95%  N_Eff  N_Eff/s  R_hat
lp__              -54  4.9e-02  1.3e+00  -5.7e+01    -53    728      421    1.0
n_leapfrog__      157  2.8e+00  1.5e+02   3.0e+00    511   3085     1784    1.0
lambda1          0.31  2.8e-01  7.1e+00  -1.2e+01     12    638      369    1.0
lambda2         -0.14  2.8e-01  7.1e+00  -1.2e+01     12    638      369    1.0
sigma             1.0  2.6e-03  8.0e-02   9.2e-01    1.2    939      543    1.0
mu               0.16  1.8e-03  1.0e-01  -8.1e-03   0.33   3289     1902    1.0
```

##### 1個のスケールパラメータ、非正則事前分布
```
Warmup took (0.011, 0.012, 0.011, 0.011) seconds, 0.044 seconds total
Sampling took (0.017, 0.020, 0.020, 0.019) seconds, 0.077 seconds total
                Mean     MCSE  StdDev        5%   50%   95%  N_Eff  N_Eff/s  R_hat
lp__             -54  2.5e-02    0.91  -5.5e+01   -53   -53   1318    17198    1.0
n_leapfrog__     3.2  2.7e-01     1.7   1.0e+00   3.0   7.0     39      507    1.0
mu              0.17  2.1e-03    0.10  -3.8e-03  0.17  0.33   2408    31417    1.0
sigma            1.0  1.6e-03   0.071   9.3e-01   1.0   1.2   2094    27321    1.0
```

図21.2: $y_n \sim \mathrm{Normal}(0, 1)$から生成した100データ点を、デフォルトのパラメータを使ってStanであてはめを行なった結果。上段は、非正則一様事前分布と尤度$y_n \sim \mathrm{Normal}(\lambda_1 + \lambda_2, \sigma)$を使った識別できないモデル。中段は、上段^[訳注: 原文はmiddleですが、誤りと思われます。]と同じ尤度で、事前分布を$\lambda_k \sim \mathrm{Normal}(0, 10)$としたもの。下段は、尤度を$y_n \sim \mathsf{Normal}(\mu, \sigma)$とした、識別できるモデル。すべてのモデルで、$\mu$はおよそ0.16と推定され、モンテカルロ標準誤差は非常に小さいのですが、事後標準偏差は0.1と大きくなっています。真の値$\mu = 0$は、3つのモデルすべてで事後分布の90%区間に含まれています。


3つの例すべてについて、Stan 2.1.0でデフォルトのパラメータ（1000ウォームアップiteration、1000サンプリングiteration、最大tree depthが10のNUTSサンプラー）を用いて当てはめを行ないました。結果は図21.2に示します。この出力から分かる主要な統計量は以下のとおりです。

* `R_hat`の列でわかるように、識別されないモデルでは$\lambda_1$と$\lambda_2$以外のパラメータはすべて収束しました。
* リープフロッグの平均ステップ数は、識別されるモデルではおよそ3、弱い事前分布で識別されるモデルでは150、識別されないモデルでは1400です。
* $\mu$の秒当たりの有効サンプルの数は、識別されるモデルではおおよそ31,000ですが、弱情報事前分布で識別されるモデルでは1900、識別されないモデルでは200です。$\sigma$の結果も同様です。
* 識別されないモデルでは、$\lambda_1$の95%区間は(-2300, 6000)でした。一方、弱情報事前分布で識別されるモデルではわずか(-12, 12)でした。
* 3つのモデルすべてで、$\mu = 0$と$\sigma = 1$のシミュレートされた値は、うまく事後分布の90%区間に収まっています。

最初の2点、収束の欠如と、リープフロッグの最大ステップ数（最大tree depthも同じ）到達は、非正則事後分布を示すものです。ギブズサンプラーで行なわれるような貧弱なサンプリングで問題を覆い隠すのではなく、ハミルトニアンモンテカルロは事後分布を探索しようとしますし、それが失敗するなら、モデルのどこかがおかしいことを明確に示しています。

