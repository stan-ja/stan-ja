## 7. 時系列モデル

時系列データは、時間軸に沿って得られるデータです。この章では2種類の時系列モデルを紹介します。1つは、自己回帰および移動平均モデルといった回帰に似たモデル、もう1つは隠れマルコフモデルです。

15章ではガウス過程を紹介しますが、これも時系列（と空間）データに使えるでしょう。

### 7.1. 自己回帰モデル

正規ノイズの1次自己回帰モデル(AR(1))では、各点$y_{n}$は次式のように生成される系列$y$にまとめられます。

![$$y_{n} \sim \mathsf{Normal}(\alpha + \beta y_{n-1}, \sigma)$$](fig/fig01.png)

すなわち、$y_{n}$の期待値は$\alpha + \beta y_{n-1}$で、ノイズの大きさは$\sigma$です。

#### AR(1)モデル

傾き（$\beta$）、切片（$\alpha$）、ノイズのスケール（$\sigma$）のパラメータに非正則平坦一様分布を設定するなら、AR(1)モデルのStanプログラムは以下のようになります。

```
data {
  int<lower=0> N;
  vector[N] y;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {
  for (n in 2:N)
    y[n] ~ normal(alpha + beta * y[n-1], sigma);
}
```

最初の観測データ点`y[1]`はここではモデル化されていません。これは条件となるものが何もないからです。そのかわり、`y[1]`は`y[2]`の条件となっています。このモデルではまた`sigma`に非正則事前分布を使っていますが、もし`y`の時間的変化のスケールに情報があるのなら、問題なく情報事前分布を加えることができます。あるいは、`y`のスケールに大ざっぱな知識があるのであれば弱情報事前分布で推定を良くすることもできます。

##### スライシングで効率よく

おそらく少し読みにくくはなりますが、上のモデルをとても効率良く記述する方法がベクトルのスライシングです。上のモデルは1行で書けます。

```
model {
  tail(y, N - 1) ~ normal(alpha + beta * head(y, N - 1), sigma);
}
```

`tail`演算は、`y`の末尾から`N - 1`個の要素を取り出すもので、`head`演算は最初の`N - 1`個を取り出すものです。`head`の要素に`beta`を掛けるのにはベクトル計算を使っています。

#### AR(1)モデルの拡張

回帰係数とノイズのスケールには、さまざまな別の分布族の正則事前分布を設定することもできるでしょう。正規分布ノイズのモデルは、スチューデントのt分布はじめ、上下限のない分布に変えることができます。複数の観測系列があるようなら、このモデルは階層的にもできるでしょう。

強制的に定常AR(1)過程として推定するなら、傾きの係数`beta`には以下のように上下限に制約をつけてもよいかもしれません。

```
real<lower=-1,upper=1> beta;
```

実際には、こうした制約はおすすめしません。データが定常でないなら、モデルのあてはめのときにそれがわかるというのが最善です。`beta`の値が零近辺に集まるような事前分布を設定することで、定常パラメーターが推定しやすくなるでしょう。

#### AR(2)モデル

このモデルの次数を拡張するのも簡単です。例えば、2次の係数`gamma`を入れて、以下のモデル文のようにAR(2)モデルをコーディングできるでしょう。

```
for (n in 3:N)
  y[n] ~ normal(alpha + beta*y[n-1] + gamma*y[n-2], sigma);
```

#### AR($K$)モデル

次数自体もデータとして与えるような一般モデルは、係数を配列に入れ、線形予測子をループ内で計算させるようにしてコーディングできます。

```
data {
  int<lower=0> K;
  int<lower=0> N;
  real y[N];
}
parameters {
  real alpha;
  real beta[K];
  real sigma;
}
model {
  for (n in (K+1):N) {
    real mu;
    mu <- alpha;
    for (k in 1:K)
      mu <- mu + beta[k] * y[n-k];
    y[n] ~ normal(mu, sigma);
  }
}
```

#### ARCH(1)モデル

計量経済学と財政学の時系列モデルでは不等分散を仮定するのが普通です（すなわち、系列を定義するノイズ項のスケールが時間的に変化してもよいとします）。そのようなモデルで最も単純なのがARCH（AugoRegressive Conditional Heteroscedasticity, 自己回帰条件付き不等分散）モデルです(Engle, 1982)。自己回帰モデルAR(1)では、系列の平均が時間的に変化しますが、ノイズ項は固定されたままです。ARCH(1)モデルでは、これとは異なり、ノイズ項のスケールが時間的に変化する一方で平均項は固定されたままです。もちろん、平均もスケールも時間的に変化するとモデルを定義することもできるでしょう。計量経済学の文献には多種多様な時系列モデリングの選択肢があります。

ARCH(1)モデルは典型的には以下の一連の式で示されます。ここで、$r_{t}$は時点$t$における収益の観測値、$\mu$、$\alpha_{0}$、$\alpha_{1}$は未知の回帰係数パラメーターです。

![$$\begin{array}{rl}r_{t} &= \mu + a_{t} \\ a_{t} &= \sigma_{t} \epsilon_{t} \\ \epsilon_{t} &\sim \mathsf{Normal}(0, 1) \\ \sigma_{t}^{2} &= \alpha_{0} + \alpha_{1}a_{t-1}^{2}\end{array}$$](fig/fig02.png)

ノイズ項$\sigma_{t}^2$が正であることを保証するため、$\alpha_{0}, \alpha_{1} > 0$と、スケール係数は正に制約されています。時系列の定常性を保証するため、$\alpha_{1} < 1$と、傾きは1未満に制約されています。<sup>1</sup>ARCH(1)モデルはStanでは以下のようにそのままコーディングできます。

```
data {
  int<lower=0> T;   // 時点の数
  real r[T];        // 時点tにおける収益
}
parameters {
  real mu;                       // 平均収益
  real<lower=0> alpha0;          // 誤差の切片
  real<lower=0,upper=1> alpha1;  // 誤差の傾き
}
model {
  for (t in 2:T)
    r[t] ~ normal(mu, sqrt(alpha0 + alpha1 * pow(r[t-1] - mu,2)));
}
```

このモデルのループは、時点$t = 1$における収益をモデル化しないように定義されています。次節のモデルで、$t = 1$における収益をモデル化する方法をお見せします。このモデルは、ベクトル化してより効率的にすることができません。次節のモデルでベクトル化の例を紹介します。

<sup>1</sup>実際には、この制約を外してみて、非定常な係数の組み合わせの方がデータによく当てはまるかどうかを試すのが有用なこともあります。あるいはまた、当てはめから外れているトレンドがあるなら明らかに非定常でしょうから、モデルにトレンド項を加えることもあります。

### 7.2. 時間的不等分散性のモデリング

一揃いの変数について、分散がすべて同じなら、等分散ということなります。一方、分散がすべて同じというわけでないなら、不等分散ということになります。不等分散の時系列モデルでは、ノイズ項が時間的に変化してもよいとします。

#### GARCH(1,1)モデル

基本的なGARCH（Generalized AutoRegressive Conditional Heteroscedasticity, 一般化自己回帰条件付き不等分散）モデルであるGARCH(1,1)はARCH(1)モデルを拡張したもので、一期前の時点$t-1$での収益の平均との差の2乗を、時点$t$のボラティリティの予測変数に含みます。

![$$\sigma_{t}^{2} = \alpha_{0} + \alpha_{1}a_{t-1}^{2} + \beta_{1}\sigma_{t-1}^{2}$$](fig/fig03.png)

スケール項が正であることと時系列が定常であることを保証するため、係数については、$\alpha_{0}, \alpha_{1}, \beta_{1} > 0$、かつ傾きについて$\alpha_{1} + \beta_{1} < 1$をすべて満たさなくてなりません。

```
data {
  int<lower=0> T;
  real r[T];
  real<lower=0> sigma1;
}
parameters {
  real mu;
  real<lower=0> alpha0;
  real<lower=0,upper=1> alpha1;
  real<lower=0,upper=(1-alpha1)> beta1;
}
transformed parameters {
  real<lower=0> sigma[T];
  sigma[1] <- sigma1;
  for (t in 2:T)
    sigma[t] <- sqrt(alpha0
                     + alpha1 * pow(r[t-1] - mu, 2)
                     + beta1 * pow(sigma[t-1], 2));
}
model {
  r ~ normal(mu,sigma);
}
```

ボラティリティ回帰の再帰的定義の最初を決めるために、$t = 1$におけるノイズのスケールとして、非負の値を持つ`sigma1`をデータ宣言に含めます。

制約はそのままパラメータ宣言でコーディングされています。この宣言は、`alpha1`の値が`beta1`に依存するという制約があるので、この順序どおりにする必要があります。

非負値の配列である変換パラメータ(transformed parameter)`sigma`は各時点のスケールの値を格納するのに使われます。これらの値の定義は`transformed parameters`ブロックにあり、回帰もここで定義されるようにしました。切片`alpha0`、1期前の収益と平均との差の2乗に対する傾き`alpha1`、1期前のノイズスケールの2乗に対する傾き`beta1`がここにあります。最後に、Stanでは正規分布には（分散パラメータではなく）スケール（偏差）パラメータが必要なので、回帰全体を`sqrt`関数の中に入れています。

`transformed parameters`ブロックに回帰を置くことにより、モデルは、ベクトル化されたサンプリング文1行にまで減りました。`r`と`sigma`の長さは`T`ですので、すべてのデータが直接モデル化されています。

### 7.3. 移動平均モデル

移動平均モデルは、過去の誤差を将来の結果の予測変数として使います。次数$Q$の移動平均モデルMA($Q$)には、全体的な平均パラメータ$\mu$と、過去の誤差項についての回帰係数$\theta_{q}$があります。時点$t$における誤差を$\epsilon_{t}$として、結果$y_{t}$についてのモデルは次のように定義されます。

![$$y_{t} = \mu + \theta_{1}\epsilon_{t-1} + \dots + \theta_{Q}\epsilon_{t-Q} + \epsilon_{t}$$](fig/fig04.png)

結果$y_{t}$についての誤差項$\epsilon_{t}$は正規分布としてモデル化されています。

![$$\epsilon_{t} \sim \mathsf{Normal}(0, \sigma)$$](fig/fig05.png)

正則なベイズモデルでは、$\mu$, $\theta$, $\sigma$にはすべて事前分布を与える必要があります。

#### MA(2)の例

MA(2)モデルはStanでは以下のようにコーディングできます。

```
data {
  int<lower=3> T;  // 観測値の数
  vector[T] y;     // 時点Tにおける観測値
}
parameters {
  real mu;              // 平均
  real<lower=0> sigma;  // 誤差のスケール
  vector[2] theta;      // ラグの係数
}
transformed parameters {
  vector[T] epsilon;    // 誤差項
  epsilon[1] <- y[1] - mu;
  epsilon[2] <- y[2] - mu - theta[1] * epsilon[1];
  for (t in 3:T)
   epsilon[t] <- ( y[t] - mu
                   - theta[1] * epsilon[t - 1]
                   - theta[2] * epsilon[t - 2] );
}
model {
  mu ~ cauchy(0,2.5);
  theta ~ cauchy(0,2.5);
  sigma ~ cauchy(0,2.5);
  for (t in 3:T)
    y[t] ~ normal(mu
                  + theta[1] * epsilon[t - 1]
                  + theta[2] * epsilon[t - 2],
                  sigma);
}
```

誤差項$\epsilon_{t}$は、観測値とパラメータを使って変換パラメータ(transformed parameter)として定義されています。（尤度を定義する）サンプリング文の定義もこれと同じ定義を使っていますが、$n > Q$の$y_{n}$にのみ適用可能です。この例では、パラメータにはコーシー事前分布（$\sigma$には半コーシー分布）を与えています。もっとも、ほかの事前分布も同じくらい簡単に使えます。

modelブロック中のサンプリング文をベクトル化すると、このモデルはもっと速くできるでしょう。ループの代わりにドット乗算を使って$\epsilon_{t}$の計算をベクトル化しても高速化できるでしょう。

#### ベクトル化したMA($Q$)モデル

サンプリング確率をベクトル化した一般的なMA($Q$)モデルは以下のように定義できるでしょう。

```
data {
  int<lower=0> Q;  // 過去のノイズ項の数
  int<lower=3> T;  // 観測値の数
  vector[T] y;     // 時点tにおける観測値
}
parameters {
  real mu;              // 平均
  real<lower=0> sigma;  // 誤差のスケール
  vector[Q] theta;      // 誤差の係数, ラグ -t
}
transformed parameters {
  vector[T] epsilon;    // 時点tにおける誤差
  for (t in 1:T) {
    epsilon[t] <- y[t] - mu;
    for (q in 1:min(t - 1, Q))
      epsilon[t] <- epsilon[t] - theta[q] * epsilon[t - q];
  }
}
model {
  vector[T] eta;
  mu ~ cauchy(0, 2.5);
  theta ~ cauchy(0, 2.5);
  sigma ~ cauchy(0, 2.5);
  for (t in 1:T) {
    eta[t] <- mu;
    for (q in 1:min(t - 1, Q))
      eta[t] <- eta[t] + theta[q] * epsilon[t - q];
  }
  y ~ normal(eta, sigma);
}
```

ここではすべてのデータがモデル化されています。不足する項は単に、誤差項の計算の際に回帰から除かれます。両方のモデルともとても速く収束し、収束した連鎖はよく混ざっています。ベクトル化したモデルの方がちょっとだけ速いのですが、これは繰り返しあたりについてのことで、収束についてではありません。というのも両者は同じモデルだからです。

### 7.4. 自己回帰移動平均モデル

ARMA（AutoRegressive Moving-Average, 自己回帰移動平均）モデルは、自己回帰モデルと移動平均モデルの予測変数を結合させたものです。履歴が1状態のARMA(1,1)モデルは、Stanでは以下のようにコーディングできます。

```
data {
  int<lower=1> T;           // 観測値の数
  real y[T];                // 観測結果
}
parameters {
  real mu;                  // 平均の係数
  real phi;                 // 自己回帰の係数
  real theta;               // 移動平均の係数
  real<lower=0> sigma;      // 誤差のスケール
}
model {
  vector[T] nu;             // 時点tでの予測値
  vector[T] err;            // 時点tでの誤差
  nu[1] <- mu + phi * mu;   // err[0] == 0と仮定
  err[1] <- y[1] - nu[1];
  for (t in 2:T) {
    nu[t] <- mu + phi * y[t-1] + theta * err[t-1];
    err[t] <- y[t] - nu[t];
  }
  mu ~ normal(0,10);        // 事前分布
  phi ~ normal(0,2);
  theta ~ normal(0,2);
  sigma ~ cauchy(0,5);
  err ~ normal(0,sigma);    // 尤度
}
```

データは他の時系列回帰と同様に宣言されており、パラメータはコード中に説明があります。

modelブロックでは、局所変数のベクトル`nu`が予測値を、`err`が誤差を格納しています。これらの計算は、前節で記述した移動平均モデルの誤差と同様です。

定常過程にするため、弱情報事前分布を設定しています。尤度は誤差項だけを含み、この例では効率的にベクトル化されています。

このようなモデルでは、計算した誤差項を調べるのが必要なことがよくあります。Stanでは、変換パラメータ(transformed parameter)として`err`を宣言することで簡単に対応できるでしょう。その場合も、上のモデルでの定義と同様です。`nu`は局所変数のままでもよいのですが、ここでは`transformed parameters`ブロックに移しましょう。

Wayne Foltaは、局所変数のベクトルを使わないモデルのコーディングを提案してくれました。以下がそれです。

```
model {
  real err;
  mu ~ normal(0,10);
  phi ~ normal(0,2);
  theta ~ normal(0,2);
  sigma ~ cauchy(0,5);
  err <- y[1] - mu + phi * mu;
  err ~ normal(0,sigma);
  for (t in 2:T) {
    err <- y[t] - (mu + phi * y[t-1] + theta * err);
    err ~ normal(0,sigma);
  }
}
```

このARMAモデルのアプローチは、Stanではどのように局所変数（この場合は`err`）を再利用できるか示す良い例となっています。Foltaのアプローチは、2つ以上の誤差項を局所変数に格納し、ループ内で再び代入することで、高次の移動平均モデルにも拡張できるでしょう。

両方のコーディングとも大変高速です。元のコーディングは正規分布をベクトル化できるという利点がありますが、使用メモリがやや多くなります。中間点は、`err`だけをベクトル化することでしょう。

#### 識別可能性と定常性

MA部分の固有多項式の解の平方根が単位円の中にあるなら、MAおよびARMAモデルは識別可能ではありません。その場合、以下の制約をつける必要があります。<sup>2</sup>

```
real<lower = -1, upper = 1> theta;
```

このモデルから生成される合成データを用いて、上の制約をつけずにモデルを走らせると、[-1,1]の範囲外に(`theta`, `phi`)の最頻値ができることがあります。これは事後分布の多峰性問題となり、またNUTSのtreedepthが非常に大きく（10を超えることもままあります）なります。制約をつけることにより、事後分布がより正確になり、treedepthが劇的に減少します。そのため、シミュレーションがかなり速くなります（典型的には1桁を大きく超えます）。

さらに、プロセスが本当に非定常なら別ですが、そうは考えられないのなら、定常性を保証するため以下の制約をつける価値があります。

```
read<lower = -1, upper = 1> phi;
```

<sup>2</sup>この小節は、Jonathan GilliganのGitHubのコメントを少し編集したものです。https://github.com/stan-dev/stan/issues/1617#issuecomment-160249142 を参照してください。

### 7.5. 確率的ボラティリティモデル

確率的ボラティリティモデルは、離散時間の潜在確率過程に従って、証券購入のオプションのような資産収益のボラティリティ（すなわち分散）を扱います(Kim et al., 1998)。データは、$T$個の等間隔時点における原資産に対する平均修正（すなわち中央化）収益$y_{t}$からなります。Kimらは、以下の回帰に似た式を使って典型的な確率ボラティリティモデルを定式化しています。ここで、潜在パラメータ$h_{t}$は対数ボラティリティを、パラメータ$\mu$は平均対数ボラティリティを、$\phi$はボラティリティ項の持続性をしめします。変数$\epsilon_{t}$は時点$t$における資産収益に対するホワイトノイズショック（すなわち乗法的誤差）で、$\delta_{t}$は時点$t$におけるボラティリティに対するショックを表します。

![$$\begin{array}{rl}y_{t} &= \epsilon_{t}\exp(h_{t}/2) \\ h_{t+1} &= \mu + \phi(h_{t}-\mu)+\delta_{t}\sigma \\ h_{1} &\sim \mathsf{Normal}\left(\mu, \frac{\sigma}{\sqrt{1-\phi^{2}}}\right) \\ \epsilon_{t} &\sim \mathsf{Normal}(0, 1), \delta_{t} \sim \mathsf{Normal}(0, 1)\end{array}$$](fig/fig06.png)

最初の行を変形すると、$\epsilon_{t} = y_{t}\exp(-h_{t}/2)$となり、$y_{t}$のサンプリング分布は以下のように書けます。

![$$y_{t} \sim \mathsf{Normal}(0, \exp(h_{t}/2))$$](fig/fig07.png)

$h_{t+1}$についての再帰式には、$\delta_{t}$のスケーリングとサンプリングを組み合わせることができて、次のサンプリング分布が得られます。

![$$h_{t+1} \sim \mathsf{Normal}(\mu + \phi(h_{t} - \mu), \sigma)$$](fig/fig08.png)

この定式化はそのままコーディングできて、以下のStanモデルになります。

```
data {
  int<lower=0> T;  // 時点(等間隔)の数
  vector[T] y;     // 時点tにおける平均修正収益
}
parameters {
  real mu;                     // 平均対数ボラティリティ
  real<lower=-1,upper=1> phi;  // ボラティリティの持続性
  real<lower=0> sigma;         // ホワイトノイズショックのスケール
  vector[T] h;                 // 時点tにおける対数ボラティリティ
}
model {
  phi ~ uniform(-1,1);
  sigma ~ cauchy(0,5);
  mu ~ cauchy(0,10);
  h[1] ~ normal(mu, sigma / sqrt(1 - phi * phi));
  for (t in 2:T)
    h[t] ~ normal(mu + phi * (h[t - 1] -  mu), sigma);
  for (t in 1:T)
    y[t] ~ normal(0, exp(h[t] / 2));
}
```

Kimらの定式化と比較すると、Stanのモデルではパラメータ$\phi$, $\sigma$, $\mu$に事前分布を与えています。ショック項$\epsilon_{t}$と$\delta_{t}$はモデル中には明示的には現れないことに注意してください。とはいえ、generated quantitiesブロックで効率的に計算することは可能でしょう。

このような確率的ボラティリティモデルの事後分布で事後分散が大きくなるのは普通のことです。例えば、 $\mu = -1.02$, $\phi = 0.95$, $\sigma = 0.25$として上のモデルで500データ点のシミュレーションを行なうと、95%事後区間は$\mu$が(-1.23,-0.54)、$\phi$が(0.82,0.98)、$\sigma$が(0.16,0.38)となります。

このモデルで生成される、秒あたりの有効サンプルを1桁以上高速化するのは比較的単純です。まず、収益$y$についてのサンプリング文は簡単にベクトル化できます。

```
y ~ normal(0, exp(h / 2));
```

これにより繰り返しは高速化されますが、有効サンブルサイズは変化しません。根本的なパラメータ化と対数確率関数は変わっていないからです。標準化ボラティリティによる再パラメータ化と、それからリスケーリングにより、連鎖の混ざり具合は改善されます。これには、`h`の代わりに、標準化パラメータ`h_std`を宣言する必要があります。

```
parameters {
  ...
  vector[T] h_std; // 時点tにおける標準化対数ボラティリティ
```

この時、元の`h`の値は`transformed parameters`ブロックで定義します。

```
transformed parameters {
  vector[T] h;            // 時点tにおける対数ボラティリティ
  h <- h_std * sigma;     // h ~ normal(0,sigma)とした
  h[1] <- h[1] / sqrt(1 - phi * phi);  // h[1]をリスケール
  h <- h + mu;
  for (t in 2:T)
    h[t] <- h[t] + phi * (h[t-1] - mu);
}
```

最初の代入では、`h_std`を$\mathsf{Normal}(0,\sigma)$という分布になるようにリスケールして、これを一時的に`h`に代入しています。2番目の代入では、`h[1]`の事前分布が`h[2]`から`h[T]`までの事前分布とは異なるように`h[1]`をリスケールしています。その次の代入では`mu`にオフセットをつけており、これにより`h[2]`から`h[T]`までが$\mathsf{Normal}(\mu,\sigma)$という分布になります。この移動は`h[1]`のリスケーリングの後に行なう必要があることに注意してください。最後のループは、`h[2]`から`h[T]`までが`phi`と`mu`と比較して適切にモデル化されるように移動平均に加算します。

最後の改良として、`h[1]`のサンプリング文と、`h[2]`から`h[T]`のサンプリングのループを、1行のベクトル化した標準正規分布のサンプリング文に置き換えます。

```
model { ...
  h_std ~ normal(0,1);
```

元のモデルでは、数百から時には数千回の繰り返しが収束に必要となることがありますが、再パラメータ化したモデルでは数十回の繰り返しで信頼できる収束に至ります。連鎖の混ざり具合も劇的に改善され、繰り返しあたりの有効サンプルサイズも多くなります。最後に、各繰り返しの時間は元のモデルのおおよそ4分の1になります。

### 7.6. 隠れマルコフモデル

隠れマルコフモデル（HMM: Hidden Markov Model）は、$T$個の出力変数$y_{t}$からなる系列を、これに並行する、潜在カテゴリカル状態変数$z_{t} \in \{1,\dots,K\}$の系列を条件として生成します。与えられた$z_{t-1}$について、$z_{t}$が他の変数と条件付き独立であるように、この「隠れ」状態変数はマルコフ連鎖を形成すると仮定します。このマルコフ連鎖は推移行列$\theta$によりパラメータ化されます。ここで、$\theta_{k}$はK次元単体（$k \in \{1,\dots,K\}$です。状態$z_{t-1}$から状態$z_{t}$への推移確率は次式のようになります。

![$$z_{t} \sim \mathsf{Categorical}(\theta_{z[t-1]})$$](fig/fig09.png)

時点$t$における出力$y_{t}$は潜在状態$z_{t}$に基づいて条件付き独立に生成されます。

この節では、出力$y_{t} \in \{1,\dots,V\}$に単純なカテゴリカルモデルを適用してHMMを記述します。潜在状態$k$についてのカテゴリカル分布はV次元単体$\phi_{k}$によりパラメータ化されます。時点$t$における出力の観測値$y_{t}$は、時点$t$における隠れ状態のインジケータ$z_{t}$に基づいて生成されます。

![$$y_{t} \sim \mathsf{Categorical}(\phi_{z[t]})$$](fig/fig10.png)

つまり、混合成分のインジケータが潜在マルコフ連鎖を形成するような離散混合分布モデルをHMMは形成しています。

#### 教師付きパラメーター推定

隠れ状態が既知の状況では、パラメータ$\theta$および$\phi$の当てはめのため、以下のナイーブモデルを使うことができます。<sup>3</sup>

```
data {
  int<lower=1> K;  // カテゴリー数
  int<lower=1> V;  // 単語数
  int<lower=0> T;  // 時点の数
  int<lower=1,upper=V> w[T]; // 単語
  int<lower=1,upper=K> z[T]; // カテゴリー
  vector<lower=0>[K] alpha;  // 推移確率の事前確率
  vector<lower=0>[V] beta;   // 出力確率の事前確率
}
parameters {
  simplex[K] theta[K];  // 推移確率
  simplex[V] phi[K];    // 出力確率
}
model {
  for (k in 1:K)
    theta[k] ~ dirichlet(alpha);
  for (k in 1:K)
    phi[k] ~ dirichlet(beta);
  for (t in 1:T)
    w[t] ~ categorical(phi[z[t]]);
  for (t in 2:T)
    z[t] ~ categorical(theta[z[t - 1]]);
}
```

$\theta_{k}$と$\phi_{k}$には明示的なディリクレ事前分布を与えています。この2文を除くと、有効な単体全体についての一様事前分布が暗黙のうちに使われることでしょう。

<sup>3</sup>このプログラムは、Stan例題モデルのリポジトリで入手できます。https://github.com/stan-dev/example-models/tree/master/misc/gaussian-process を参照してください。

#### 開始状態と終了状態の確率

動くことは動きますが、上のようにHMMを記述しても完全ではありません。開始状態$z_{1}$がモデル化されていないからです（添字は2から$T$までです）。データを長い過程の部分系列と考えるなら、$z_{1}$の確率は、マルコフ連鎖の定常状態確率に合わせるべきでしょう。この場合、データには明確な終了がなく、系列が$z_{T}$で終了する確率をモデル化する必要はありません。

もうひとつ別の概念として、HMMは有限長の系列のモデルとして考えることもできます。例えば、自然言語の文には明確な開始の分布（通常は大文字）と、終了の分布（通常は何らかの句読点）とがあります。文の境界をモデル化する最も単純な方法は、新しい潜在状態$K+1$を加え、パラメータのベクトル$\theta_{K+1}$によりカテゴリカル分布から最初の状態を生成し、状態$K+1$への推移が文の終了時にのみ起こり、それ以外では起こらないように推移を制限することです。

#### 十分統計量の計算

上に紹介したナイーブなHMM推定モデルは、カテゴリカル分布についてのループを単一の多項分布に置き換えることで劇的に速くすることができます。<sup>4</sup>データは前もって宣言しますが、ここでは`transformed data`ブロックで、推移行列と出力行列を推定する十分統計量を計算することにします。

```
transformed data {
  int<lower=0> trans[K,K];
  int<lower=0> emit[K,V];
  for (k1 in 1:K)
    for (k2 in 1:K)
      trans[k1,k2] <- 0;
  for (t in 2:T)
    trans[z[t - 1], z[t]] <- 1 + trans[z[t - 1], z[t]];
  for (k in 1:K)
    for (v in 1:V)
      emit[k,v] <- 0;
  for (t in 1:T)
    emit[z[t], w[t]] <- 1 + emit[z[t], w[t]];
}
```

入力についてのループに基づくモデルの尤度成分は以下のように多項分布に置き換わります。

```
model {
  ...
  for (k in 1:K)
    trans[k] ~ multinomial(theta[k]);
  for (k in 1:K)
    emit[k] ~ multinomial(phi[k]);
}
```

正規出力確率で連続値のHMMも、同様に十分統計量を計算することで高速化できるでしょう。

<sup>4</sup>このモデルはStan例題モデルリポジトリにあります。http://mc-stan.org/documentation を参照してください。

#### 解析的事後分布

ディリクレ-多項HMMでは、ディリクレ分布が多項分布の共益事前分布なので、事後分布は解析的に計算できます。以下の例<sup>5</sup>では、Stanのモデルがどのように事後分布を解析的に定義できるかを示します。Stan言語ではこれが可能です。というのは、データが与えられたもとで、パラメータの条件付き確率に比例する量をモデルが定義しさえすればよいからです。これには、（正規化されていない）同時確率か、（正規化されていない）条件付き確率か、あるいはその間の量を定義すればよいのです。

このモデルは、前のモデルと同じデータとパラメータを用いますが、`transformed data`ブロックで事後ディリクレパラメータを計算するようにしています。

```
transformed data {
  vector<lower=0>[K] alpha_post[K];
  vector<lower=0>[V] beta_post[K];
  for (k in 1:K)
    alpha_post[k] <- alpha;
  for (t in 2:T)
    alpha_post[z[t-1],z[t]] <- alpha_post[z[t-1],z[t]] + 1;
  for (k in 1:K)
    beta_post[k] <- beta;
  for (t in 1:T)
    beta_post[z[t],w[t]] <- beta_post[z[t],w[t]] + 1;
}
```

事後分布は以下のように解析的に書くことができます。

```
model {
  for (k in 1:K)
    theta[k] ~ dirichlet(alpha_post[k]);
  for (k in 1:K)
    phi[k] ~ dirichlet(beta_post[k]);
}
```

<sup>5</sup>このプログラムはStan例題モデルリポジトリにあります。http://mc-stan.org/documentation を参照してください。

#### 半教師付き推定

潜在状態が既知であるデータがまったくない完全に教師なしの方法でもHMMは推定ができます。その結果の事後分布は極端に多峰になるのが典型的です。中間の解法は、半教師付き推定を使うことです。これは、教師付きデータと教師なしデータとの組み合わせに基づいています。この推定戦略をStanで実装するには、未知の状態系列に対する出力系列の確率の計算が必要です。これは周辺化の問題で、HMMでは、前向きアルゴリズムと呼ばれる方法で計算されます。

Stanでは、前向きアルゴリズムは以下のようにコーディングされます。<sup>6</sup>まず、教師なしデータのためデータ変数を2つ追加で宣言します。

```
data {
  ...
  int<lower=1> T_unsup;  // 教師なしアイテムの数
  int<lower=1,upper=V> u[T_unsup]; // 教師なしワード
  ...
```

教師付きデータのモデルは変更ありません。教師なしデータは、以下のように前向きアルゴリズムをStanで実装して扱います。

```
model {
  ...
  {
    real acc[K];
    real gamma[T_unsup,K];
    for (k in 1:K)
      gamma[1,k] <- log(phi[k,u[1]]);
    for (t in 2:T_unsup) {
      for (k in 1:K) {
        for (j in 1:K)
          acc[j] <- gamma[t-1,j] + log(theta[j,k]) + log(phi[k,u[t]]);
        gamma[t,k] <- log_sum_exp(acc);
      }
    }
    increment_log_prob(log_sum_exp(gamma[T_unsup]));
  }
```

前向きの値`gamma[t,k]`は、時点`t`までの入力`u[1],...,u[t]`と、潜在状態が時点`t`で`k`に等しいことの対数周辺確率であるとして定義されます。このとき、その前の潜在状態は周辺化消去されます。`gamma`の最初の行（`gamma[1,k]`）は、潜在状態`k`が最初の出力`u[1]`を生成する対数確率で初期化されています。前と同じように、最初の潜在状態の確率自体はモデル化されません。以降の時点`t`と出力`j`について`acc[j]`の値が設定されます。`acc[j]`の値は次の3つの対数確率の和です。それは時点`t-1`の潜在状態が`j`である対数確率、時点`t-1`に状態`j`だったのが時点`t`に状態`k`に推移する対数確率、出力`u[t]`が状態`k`から生成される対数確率です。`log_sum_exp`演算は単に、状態`j`の各事前確率を掛け合わせるだけです。ただし、対数スケールにおいて算術的に安定な方法で行います。

中括弧で、局所変数`acc`と`gamma`のスコープを示しています。もっと前に宣言することもできたのですが、使用される場所の近くに宣言を置いておく方がわかりやすいでしょう。

#### 予測推論

推移パラメータ$\theta_{k,k'}$および出力パラメータ$\phi_{k,v}$、それに観測系列$u_{1},\dots,u_{T} \in {1,\dots,V}$が与えられたとき、観測された出力$u$を生成した可能性が最も高い状態系列は、Viterbi（動的プログラミング）アルゴリズムにより計算されます。

ViterbiアルゴリズムはStanでは、以下のように`generated quantities`ブロックでコーディングできます。この場合の予測値は、観測値の配列`u[1], ..., u[T_unsup]`のもとでの最も可能性の高い状態系列`y_star[1], ..., y_star[T_unsup]`です。この系列は、推移確率`theta`と出力確率`phi`により決定されるので、事後のサンプルによって異なることがあります。

```
generated quantities {
  int<lower=1,upper=K> y_star[T_unsup];
  real log_p_y_star;
  {
    int back_ptr[T_unsup,K];
    real best_logp[T_unsup,K];
    real best_total_logp;
    for (k in 1:K)
      best_logp[1,K] <- log(phi[k,u[1]]);
    for (t in 2:T_unsup) {
      for (k in 1:K) {
        best_logp[t,k] <- negative_infinity();
        for (j in 1:K) {
          real logp;
          logp <- best_logp[t-1,j]
                  + log(theta[j,k]) + log(phi[k,u[t]]);
          if (logp > best_logp[t,k]) {
            back_ptr[t,k] <- j;
            best_logp[t,k] <- logp;
          }
        }
      }
    }
    log_p_y_star <- max(best_logp[T_unsup]);
    for (k in 1:K)
      if (best_logp[T_unsup,k] == log_p_y_star)
        y_star[T_unsup] <- k;
    for (t in 1:(T_unsup - 1))
      y_star[T_unsup - t] <- back_ptr[T_unsup - t + 1,
                                      y_star[T_unsup - t + 1]];
  }
}
```

中括弧のブロックで、3つの変数`back_ptr`, `best_logp`, `best_total_logp`を局所変数にしています。そのため、これらは出力には含まれません。変数`y_star`は、入力系列`u`のもとで最も高い確率を持つラベル系列を保持します。中間量は、前向きアルゴリズムでは合計確率でしたが、それとは異なり、時点`t`までの系列についての、時点`t`で最終の出力カテゴリーが`k`である確率の最大値`best_logp[t,k]`からなります。また、リンク元へのバックポインタがあり、最終の時点`t`での対数確率の最大値からバックポインタをたどることで、最も可能性の高い状態系列が得られます。

この推論は、半教師付きモデルへの当てはめに使えるのと同様に、教師なし出力`u`でも使えます。上のコードは、教師なしの当てはめと同じモデルファイルでも使うことができます。これは、モデルをトレーニングするのに半教師付き法でデータを使うという、ベイズの推定法です。これは「ズル」ではありません。`u`についての元の状態は決して観測されないからです。他のパラメータすべてを使って推定されるだけです。

もし出力`u`が半教師付き推定では使われず、単に予測のもととなるだけなら、カット演算を使ってBUGSモデリング言語で記述したものと結果は同じです。すなわち、モデルは`u`とは独立に当てはめられており、そして、`u`を生成したものとして最も可能性の高い状態を見つけるのにパラメータが使われています。
